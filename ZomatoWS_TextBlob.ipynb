{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\sarav\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: vadersentiment in c:\\users\\sarav\\anaconda3\\lib\\site-packages (3.2.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\sarav\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob vadersentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\sarav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sarav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horrible\n",
      "waiter mis-understood\n",
      "n't drink\n",
      "never\n",
      "horrible\n"
     ]
    }
   ],
   "source": [
    "blob = TextBlob(\"Horrible service. The waiter mis-understood the drinks that we ordered. When we pointed it out to him, he took them back , and still charged us. He blamed it on us... We didn't drink them , and he took them back completely full. I regret not making a complain to the manager. Never going back.. Horrible service.\")\n",
    "for np in blob.noun_phrases:\n",
    "    print (np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_1 = blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Horrible service. The waiter his-understood the drinks that we ordered. When we pointed it out to him, he took them back , and still charged us. He blamed it on us... He didn't drink them , and he took them back completely full. I regret not making a complain to the manager. Never going back.. Horrible service.\")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Horrible JJ\n",
      "service NN\n",
      "The DT\n",
      "waiter NN\n",
      "his-understood NN\n",
      "the DT\n",
      "drinks NNS\n",
      "that IN\n",
      "we PRP\n",
      "ordered VBD\n",
      "When WRB\n",
      "we PRP\n",
      "pointed VBD\n",
      "it PRP\n",
      "out RP\n",
      "to TO\n",
      "him PRP\n",
      "he PRP\n",
      "took VBD\n",
      "them PRP\n",
      "back RP\n",
      "and CC\n",
      "still RB\n",
      "charged VBD\n",
      "us PRP\n",
      "He PRP\n",
      "blamed VBD\n",
      "it PRP\n",
      "on IN\n",
      "us PRP\n",
      "He PRP\n",
      "did VBD\n",
      "n't RB\n",
      "drink VB\n",
      "them PRP\n",
      "and CC\n",
      "he PRP\n",
      "took VBD\n",
      "them PRP\n",
      "back RP\n",
      "completely RB\n",
      "full JJ\n",
      "I PRP\n",
      "regret VBP\n",
      "not RB\n",
      "making VBG\n",
      "a DT\n",
      "complain NN\n",
      "to TO\n",
      "the DT\n",
      "manager NN\n",
      "Never RB\n",
      "going VBG\n",
      "back.. RBR\n",
      "Horrible JJ\n",
      "service NN\n"
     ]
    }
   ],
   "source": [
    "for words, tag in blob_1.tags:\n",
    "    print (words, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['service', 'waiter', 'his-understood', 'complain', 'manager', 'service']\n"
     ]
    }
   ],
   "source": [
    "nouns = []\n",
    "for words, tag in blob_1.tags:\n",
    "    if tag == \"NN\":\n",
    "        nouns.append(words)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.27499999999999997, subjectivity=0.425)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.27499999999999997, subjectivity=0.425)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_1.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27499999999999997"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_1.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rowdy', 'place']\n",
      "['place', 'and']\n",
      "['and', 'they']\n",
      "['they', 'have']\n",
      "['have', 'a']\n",
      "['a', 'butcher']\n",
      "['butcher', 'not']\n",
      "['not', 'a']\n",
      "['a', 'cooper']\n",
      "['cooper', 'or']\n",
      "['or', 'a']\n",
      "['a', 'chef']\n"
     ]
    }
   ],
   "source": [
    "# for ngram in blob_1.ngrams(2):\n",
    "#     print(ngram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
